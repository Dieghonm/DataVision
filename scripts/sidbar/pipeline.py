import streamlit as st
from zold.data_loader import load_dataset

class PipelineUI:
    def __init__(self):
        self.current_data = None
        self._init_session_state()

    def _init_session_state(self):
        """Inicializa o estado da sessÃ£o"""
        if 'current_data' not in st.session_state:
            st.session_state.current_data = None
        if 'dataset_name' not in st.session_state:
            st.session_state.dataset_name = None
        if 'last_data_source' not in st.session_state:
            st.session_state.last_data_source = None
        if 'last_uploaded_file' not in st.session_state:
            st.session_state.last_uploaded_file = None

    def _load_dataset(self, data_source, uploaded_file=None):
        """Carrega um dataset"""
        try:
            df, name = load_dataset(data_source, uploaded_file)
            return df, name
        except Exception as e:
            st.error(f"Erro ao carregar dataset: {str(e)}")
            return None, None

    def _render_algorithm_params(self, algorithm):
        """Renderiza parÃ¢metros especÃ­ficos do algoritmo"""
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ”§ ParÃ¢metros do Algoritmo")
        
        if algorithm == "random_forest":
            n_estimators = st.sidebar.slider(
                "N Estimators", 
                min_value=10, max_value=500, value=100, step=10,
                help="NÃºmero de Ã¡rvores na floresta"
            )
            max_depth = st.sidebar.slider(
                "Max Depth", 
                min_value=1, max_value=50, value=10,
                help="Profundidade mÃ¡xima das Ã¡rvores"
            )
            return {"n_estimators": n_estimators, "max_depth": max_depth}

        elif algorithm == "logistic_regression":
            c_value = st.sidebar.slider(
                "C (RegularizaÃ§Ã£o)", 
                min_value=0.01, max_value=10.0, value=1.0, step=0.01,
                help="ForÃ§a da regularizaÃ§Ã£o (valores menores = mais regularizaÃ§Ã£o)"
            )
            max_iter = st.sidebar.slider(
                "Max Iterations", 
                min_value=100, max_value=1000, value=100, step=50,
                help="NÃºmero mÃ¡ximo de iteraÃ§Ãµes"
            )
            return {"C": c_value, "max_iter": max_iter}

        elif algorithm == "svm":
            kernel = st.sidebar.selectbox(
                "Kernel", 
                ["linear", "rbf", "poly"],
                help="Tipo de kernel para o SVM"
            )
            c_value = st.sidebar.slider(
                "C (RegularizaÃ§Ã£o)", 
                min_value=0.01, max_value=10.0, value=1.0, step=0.01,
                help="ParÃ¢metro de regularizaÃ§Ã£o"
            )
            return {"kernel": kernel, "C": c_value}

        return {}

    def _execute_pipeline(self, config):
        """Executa o pipeline com as configuraÃ§Ãµes fornecidas"""
        try:
            st.success("ğŸš€ Pipeline iniciado!")
            
            # Criar uma barra de progresso
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Simular etapas do pipeline
            steps = [
                "Carregando dados...",
                "Preprocessando dados...",
                "Dividindo dataset...",
                "Treinando modelo...",
                "Avaliando modelo...",
                "Salvando resultados..."
            ]
            
            for i, step in enumerate(steps):
                status_text.text(step)
                progress_bar.progress((i + 1) / len(steps))
                # Simular tempo de processamento
                import time
                time.sleep(0.5)
            
            status_text.text("âœ… Pipeline concluÃ­do!")
            
            # Mostrar configuraÃ§Ã£o utilizada
            with st.expander("ğŸ“‹ ConfiguraÃ§Ã£o Utilizada"):
                col1, col2 = st.columns(2)
                with col1:
                    st.json({
                        "data_source": config["data_source"],
                        "algorithm": config["algorithm"],
                        "test_size": config["test_size"],
                        "cv_folds": config["cv_folds"]
                    })
                with col2:
                    st.json({
                        "metrics": config["metrics"],
                        "algo_params": config["algo_params"],
                        "steps": config["steps"]
                    })
            
            st.info("âš ï¸ Esta Ã© uma simulaÃ§Ã£o. Conecte as funÃ§Ãµes reais do pipeline aqui.")
            
        except Exception as e:
            st.error(f"Erro na execuÃ§Ã£o do pipeline: {str(e)}")

    def render_pipeline(self):
        """Renderiza a sidebar do pipeline UI"""
        st.sidebar.title("âš™ï¸ ConfiguraÃ§Ãµes do Pipeline")

        # ğŸ“‚ Fonte dos dados
        st.sidebar.subheader("ğŸ“‚ Dados")
        data_source = st.sidebar.selectbox(
            "Fonte de dados:",
            ["upload", "iris", "wine", "breast_cancer", "Credit", "Hipertension", "Phone addiction"],
            help="Escolha um dataset prÃ©-definido ou faÃ§a upload",
            key="data_source_select"
        )

        uploaded_file = None
        if data_source == "upload":
            uploaded_file = st.sidebar.file_uploader(
                "Upload CSV:", 
                type=['csv'],
                help="FaÃ§a upload do seu dataset em CSV",
                key="file_upload"
            )

        # Verificar se precisa recarregar os dados
        data_changed = (
            data_source != st.session_state.get('last_data_source') or
            uploaded_file != st.session_state.get('last_uploaded_file')
        )

        if data_changed:
            with st.spinner("Carregando dataset..."):
                self.current_data, dataset_name = self._load_dataset(data_source, uploaded_file)
                st.session_state.current_data = self.current_data
                st.session_state.dataset_name = dataset_name
                st.session_state.last_data_source = data_source
                st.session_state.last_uploaded_file = uploaded_file

        # Recuperar dados da sessÃ£o
        self.current_data = st.session_state.get('current_data')

        # Mostrar info do dataset se carregado
        if self.current_data is not None:
            st.sidebar.success(f"âœ… {st.session_state.get('dataset_name', 'Dataset')} carregado")
            st.sidebar.info(f"ğŸ“Š Shape: {self.current_data.shape}")

        # ğŸ¤– Modelo
        st.sidebar.subheader("ğŸ¤– Modelo")
        algorithm = st.sidebar.selectbox(
            "Algoritmo:",
            ["random_forest", "logistic_regression", "svm"],
            help="Escolha o algoritmo de ML"
        )

        algo_params = self._render_algorithm_params(algorithm)

        # ğŸ“Š AvaliaÃ§Ã£o
        st.sidebar.subheader("ğŸ“Š AvaliaÃ§Ã£o")
        test_size = st.sidebar.slider(
            "Tamanho do teste:", 
            min_value=0.1, max_value=0.5, value=0.2, step=0.05,
            help="ProporÃ§Ã£o dos dados para teste"
        )
        cv_folds = st.sidebar.slider(
            "Cross-validation:", 
            min_value=3, max_value=10, value=5,
            help="NÃºmero de folds para validaÃ§Ã£o cruzada"
        )

        metrics = st.sidebar.multiselect(
            "MÃ©tricas:",
            ["accuracy", "precision", "recall", "f1", "roc_auc"],
            default=["accuracy", "f1"],
            help="MÃ©tricas de avaliaÃ§Ã£o do modelo"
        )

        # ğŸ”§ Pipeline
        st.sidebar.subheader("ğŸ”§ Pipeline")
        steps = st.sidebar.multiselect(
            "Etapas:",
            ["load_data", "preprocess_data", "train_model", "evaluate_model", "save_results"],
            default=["load_data", "preprocess_data", "train_model", "evaluate_model"],
            help="Etapas do pipeline a serem executadas"
        )

        # âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas
        with st.sidebar.expander("âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas"):
            scaling = st.selectbox(
                "NormalizaÃ§Ã£o:", 
                ["standard", "minmax", "robust", "none"],
                help="Tipo de normalizaÃ§Ã£o dos dados"
            )
            random_state = st.number_input(
                "Random State:", 
                value=42, min_value=0, max_value=999,
                help="Semente para reprodutibilidade"
            )

        # ğŸš€ Executar Pipeline
        st.sidebar.markdown("---")
        if self.current_data is not None:
            if st.sidebar.button("ğŸš€ Executar Pipeline", type="primary", use_container_width=True):
                config = {
                    "data_source": data_source,
                    "uploaded_file": uploaded_file,
                    "algorithm": algorithm,
                    "algo_params": algo_params,
                    "test_size": test_size,
                    "cv_folds": cv_folds,
                    "metrics": metrics,
                    "steps": steps,
                    "scaling": scaling,
                    "random_state": random_state
                }
                self._execute_pipeline(config)
        else:
            st.sidebar.warning("ğŸ‘† Selecione um dataset para continuar")

        return {
            "data_source": data_source,
            "uploaded_file": uploaded_file,
            "algorithm": algorithm,
            "algo_params": algo_params,
            "test_size": test_size,
            "cv_folds": cv_folds,
            "metrics": metrics,
            "steps": steps,
            "scaling": scaling,
            "random_state": random_state
        }

def pipeline_sidebar():
    """FunÃ§Ã£o principal para renderizar o sidebar do pipeline"""
    pipeline_ui = PipelineUI()
    return pipeline_ui.render_pipeline()